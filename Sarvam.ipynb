{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym0T3KistS-m",
        "outputId": "3bc3b549-0bb4-45d0-909a-96949774647a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nRDjiq8XtQb6"
      },
      "outputs": [],
      "source": [
        "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w0JNcN_5u6-6"
      },
      "outputs": [],
      "source": [
        "# # Load BLIP-2 Model and Processor\n",
        "# model_name = \"Salesforce/blip2-flan-t5-xl\"\n",
        "# processor = Blip2Processor.from_pretrained(model_name)\n",
        "# model = Blip2ForConditionalGeneration.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSG68c9CfNpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIKDxhnbwCL_"
      },
      "source": [
        "**Simple VQA using llama vision using groq api , sarvam api for tts and stt**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCXqX0syhCvO",
        "outputId": "5d953256-91f9-4826-c129-97b8fde82371"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests pillow pyttsx3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MFrG5izhlF2",
        "outputId": "f4fd19e8-6f7d-4b5e-a293-df703a5a41df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Collecting pyttsx3\n",
            "  Downloading pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Downloading pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: pyttsx3\n",
            "Successfully installed pyttsx3-2.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWpp7b_-iLkN",
        "outputId": "9990cb5d-4326-4caa-eb92-5a769cf1a95d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.12.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "1gMCs-ZS4WZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "# API details for Sarvam Speech-to-Text\n",
        "SARVAM_API_URL = \"https://api.sarvam.ai/speech-to-text\"\n",
        "API_SUBSCRIPTION_KEY = \"9ad8976b-6ad1-4994-bea4-87c914bda6db\"  # Replace with your Sarvam API key\n",
        "LANGUAGE_CODE = \"hi-IN\"  # Language code (e.g., hi-IN for Hindi)\n",
        "MODEL = \"saarika:v1\"  # Model version\n",
        "\n",
        "# Groq API details for Vision Model\n",
        "from groq import Groq\n",
        "groq_api_key =\"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\"\n",
        "groq_client = Groq(\n",
        "    api_key=groq_api_key,\n",
        ")\n",
        "\n",
        "# Function to transcribe audio with Sarvam\n",
        "def transcribe_audio(audio_path):\n",
        "    # Ensure the file has the correct extension\n",
        "    if not audio_path.lower().endswith((\".wav\", \".mp3\")):\n",
        "        print(\"Error: The file must be in .wav or .mp3 format.\")\n",
        "        return None\n",
        "\n",
        "    # Open and send the file to the API\n",
        "    with open(audio_path, \"rb\") as file:\n",
        "        files = {\"file\": (audio_path, file, \"audio/wav\")}  # Explicitly set the file MIME type\n",
        "        data = {\n",
        "            \"language_code\": LANGUAGE_CODE,\n",
        "            \"model\": MODEL,\n",
        "            \"with_timestamps\": \"true\"\n",
        "        }\n",
        "        headers = {\"api-subscription-key\": API_SUBSCRIPTION_KEY}\n",
        "\n",
        "        print(\"Sending audio to Sarvam API...\")\n",
        "        response = requests.post(SARVAM_API_URL, headers=headers, files=files, data=data)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            transcript = result.get(\"transcript\", \"\")\n",
        "            print(\"Transcription successful:\", transcript)\n",
        "            return transcript\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "def transcribe_and_translate_audio(audio_path):\n",
        "    # Ensure the file has the correct extension\n",
        "    if not audio_path.lower().endswith((\".wav\", \".mp3\")):\n",
        "        print(\"Error: The file must be in .wav or .mp3 format.\")\n",
        "        return None\n",
        "\n",
        "    # Open and send the file to the Speech-to-Text-Translate API\n",
        "    with open(audio_path, \"rb\") as file:\n",
        "        files = {\"file\": (audio_path, file, \"audio/wav\")}  # Explicitly set the file MIME type\n",
        "        data = {\n",
        "            \"model\": \"saaras:v1\",\n",
        "            \"prompt\": \"\"  # Optional: Add a context-specific prompt here\n",
        "        }\n",
        "        headers = {\"api-subscription-key\": API_SUBSCRIPTION_KEY}\n",
        "\n",
        "        print(\"Sending audio to Sarvam Speech-to-Text-Translate API...\")\n",
        "        response = requests.post(\"https://api.sarvam.ai/speech-to-text-translate\", headers=headers, files=files, data=data)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            transcript = result.get(\"transcript\", \"\")\n",
        "            language_code = result.get(\"language_code\", \"unknown\")\n",
        "            print(f\"Transcription successful (Detected Language: {language_code}): {transcript}\")\n",
        "            return transcript\n",
        "        else:\n",
        "            print(f\"Error {response.status_code}: {response.text}\")\n",
        "            return None\n",
        "from PIL import Image\n",
        "import base64\n",
        "import io\n",
        "\n",
        "def encode_image_to_base64(image_path):\n",
        "    \"\"\"Convert image to base64 string\"\"\"\n",
        "    with Image.open(image_path) as img:\n",
        "        # Convert image to RGB if it's not\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        # Create a byte buffer\n",
        "        buffer = io.BytesIO()\n",
        "        img.save(buffer, format='JPEG')\n",
        "        image_bytes = buffer.getvalue()\n",
        "\n",
        "        # Encode to base64\n",
        "        base64_image = base64.b64encode(image_bytes).decode('utf-8')\n",
        "        return f\"data:image/jpeg;base64,{base64_image}\"\n",
        "\n",
        "def process_image_and_query(image_path, query):\n",
        "    # Convert image to base64\n",
        "    image_data_url = encode_image_to_base64(image_path)\n",
        "\n",
        "    # Prepare the messages for LLaVA model\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": query\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": image_data_url\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Send request to Groq's LLaVA model\n",
        "    print(\"Sending query to LLaVA model...\")\n",
        "    completion = groq_client.chat.completions.create(\n",
        "        model=\"llava-v1.5-7b-4096-preview\",\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False,\n",
        "        stop=None\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "def translate_text(text, target_lang_code):\n",
        "    \"\"\"\n",
        "    Translates text to target language using Sarvam.ai API\n",
        "    Args:\n",
        "        text (str): Text to translate\n",
        "        target_lang_code (str): Target language code (e.g., 'hi-IN', 'ta-IN', 'te-IN', etc.)\n",
        "    Returns:\n",
        "        str: Translated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = \"https://api.sarvam.ai/translate\"\n",
        "\n",
        "        payload = {\n",
        "            \"input\": text,\n",
        "            \"source_language_code\": \"en-IN\",  # Source is English\n",
        "            \"target_language_code\": target_lang_code,\n",
        "            \"speaker_gender\": \"Male\",\n",
        "            \"mode\": \"formal\",\n",
        "            \"model\": \"mayura:v1\",\n",
        "            \"enable_preprocessing\": True\n",
        "        }\n",
        "\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"api-subscription-key\":  API_SUBSCRIPTION_KEY # Replace with your Sarvam.ai API key\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            return response.json()['translated_text']  # Adjust based on actual API response structure\n",
        "        else:\n",
        "            print(f\"Translation failed with status code: {response.status_code}\")\n",
        "            print(f\"Error message: {response.text}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Translation error: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_supported_languages():\n",
        "    \"\"\"\n",
        "    Returns a dictionary of supported languages and their codes\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"Hindi\": \"hi-IN\",\n",
        "        \"Tamil\": \"ta-IN\",\n",
        "        \"Telugu\": \"te-IN\",\n",
        "        \"Kannada\": \"kn-IN\",\n",
        "        \"Malayalam\": \"ml-IN\",\n",
        "        \"Marathi\": \"mr-IN\",\n",
        "        \"Bengali\": \"bn-IN\",\n",
        "        \"Gujarati\": \"gu-IN\",\n",
        "        \"Punjabi\": \"pa-IN\",\n",
        "        \"Odia\": \"or-IN\",\n",
        "        # Add more languages as supported by Sarvam.ai\n",
        "    }\n",
        "\n",
        "\n",
        "def text_to_speech(text, target_language_code=\"hi-IN\"):\n",
        "    \"\"\"\n",
        "    Converts text to speech using the provided API and saves the audio as a .wav file.\n",
        "    \"\"\"\n",
        "    url = \"https://api.sarvam.ai/text-to-speech\"\n",
        "\n",
        "    payload = {\n",
        "        \"inputs\": [text],\n",
        "        \"target_language_code\": target_language_code,\n",
        "        \"speaker\": \"meera\",  # You can change the speaker here\n",
        "        \"pitch\": 0,\n",
        "        \"pace\": 1.65,\n",
        "        \"loudness\": 1.5,\n",
        "        \"speech_sample_rate\": 8000,\n",
        "        \"enable_preprocessing\": True,\n",
        "        \"model\": \"bulbul:v1\"\n",
        "    }\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-subscription-key\": API_SUBSCRIPTION_KEY\n",
        "    }\n",
        "\n",
        "    # Sending request to the Sarvam AI API\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Get the audio content (assuming it's in MP3 format)\n",
        "        audio_data = response.json()['audios'][0]  # Extracting the base64 audio data\n",
        "        return audio_data\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert base64 audio data to WAV and play it\n",
        "def save_and_play_audio(base64_audio_data, output_path='output_audio.wav'):\n",
        "    \"\"\"\n",
        "    Decodes base64 audio data, saves it as a .wav file, and plays it.\n",
        "    \"\"\"\n",
        "    # Decode the base64 audio data\n",
        "    audio_data = base64.b64decode(base64_audio_data)\n",
        "\n",
        "    # Save the audio data as a WAV file\n",
        "    with open(output_path, 'wb') as audio_file:\n",
        "        audio_file.write(audio_data)\n",
        "\n",
        "    # Play the audio\n",
        "    ipd.Audio(output_path)\n",
        "\n",
        "def chatbot_colab_translate():\n",
        "    print(\"Welcome to the Visual Assistant Chatbot in Colab!\")\n",
        "\n",
        "    # Display supported languages\n",
        "    supported_langs = get_supported_languages()\n",
        "    print(\"\\nSupported Languages:\")\n",
        "    for lang, code in supported_langs.items():\n",
        "        print(f\"- {lang} ({code})\")\n",
        "\n",
        "    # Get target language from user\n",
        "    print(\"\\nEnter the language code for translation (e.g., 'hi-IN' for Hindi):\")\n",
        "    target_language = input().strip()\n",
        "\n",
        "    if target_language not in supported_langs.values():\n",
        "        print(f\"Warning: '{target_language}' might not be supported. Proceeding anyway...\")\n",
        "\n",
        "    # Step 1: Upload audio file for transcription\n",
        "    print(\"\\nPlease upload an audio file (.wav or .mp3) for transcription and translation.\")\n",
        "    audio_upload = files.upload()  # User uploads an audio file\n",
        "    audio_path = list(audio_upload.keys())[0]  # Get the uploaded file path\n",
        "\n",
        "    # Transcribe the uploaded audio\n",
        "    transcript = transcribe_and_translate_audio(audio_path)\n",
        "    if not transcript:\n",
        "        print(\"Audio transcription failed. Please ensure the file is in .wav or .mp3 format and try again.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Transcript: {transcript}\")\n",
        "\n",
        "    # Step 2: Upload an image for visual question answering\n",
        "    print(\"\\nPlease upload an image file for analysis.\")\n",
        "    image_upload = files.upload()  # User uploads an image file\n",
        "    image_path = list(image_upload.keys())[0]  # Get the uploaded file path\n",
        "\n",
        "    # Step 3: Use the translated transcription as the query for the vision model\n",
        "    vision_response = process_image_and_query(image_path, transcript)\n",
        "\n",
        "    # Step 4: Translate the final vision response to target language\n",
        "    translated_response = translate_text(vision_response, target_language)\n",
        "\n",
        "    print(f\"\\nChatbot Response (English): {vision_response}\")\n",
        "    print(f\"Chatbot Response (Translated): {translated_response}\")\n",
        "\n",
        "    # Step 5: Convert the translated response to speech and play it\n",
        "    base64_audio_data = text_to_speech(translated_response,target_language)\n",
        "\n",
        "    if base64_audio_data:\n",
        "        save_and_play_audio(base64_audio_data)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function with error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import requests\n",
        "    except ImportError:\n",
        "        !pip install requests\n",
        "\n",
        "    try:\n",
        "        chatbot_colab_translate()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcess interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")\n",
        "        print(\"Please make sure you have set up the API key correctly and have internet connection.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "CAYTOjjQhjjP",
        "outputId": "2cef76f6-d515-46e2-dc55-65a1407867a3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Visual Assistant Chatbot in Colab!\n",
            "\n",
            "Supported Languages:\n",
            "- Hindi (hi-IN)\n",
            "- Tamil (ta-IN)\n",
            "- Telugu (te-IN)\n",
            "- Kannada (kn-IN)\n",
            "- Malayalam (ml-IN)\n",
            "- Marathi (mr-IN)\n",
            "- Bengali (bn-IN)\n",
            "- Gujarati (gu-IN)\n",
            "- Punjabi (pa-IN)\n",
            "- Odia (or-IN)\n",
            "\n",
            "Enter the language code for translation (e.g., 'hi-IN' for Hindi):\n",
            "hi-IN\n",
            "\n",
            "Please upload an audio file (.wav or .mp3) for transcription and translation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c0cf530f-20fc-47d7-bf08-7cae6cec05f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c0cf530f-20fc-47d7-bf08-7cae6cec05f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hindi_question.wav to hindi_question (14).wav\n",
            "Sending audio to Sarvam Speech-to-Text-Translate API...\n",
            "Transcription successful (Detected Language: hi-IN): What all things are there in this picture?\n",
            "Transcript: What all things are there in this picture?\n",
            "\n",
            "Please upload an image file for analysis.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dc77959a-eb81-4c84-b11a-a5ae31acd395\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dc77959a-eb81-4c84-b11a-a5ae31acd395\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heartwarming-moment-between-dog-cat-600nw-2432338827 (1).webp to heartwarming-moment-between-dog-cat-600nw-2432338827 (1) (13).webp\n",
            "Sending query to LLaVA model...\n",
            "\n",
            "Chatbot Response (English): In this picture, there is a dog and a cat playing together in a grassy area. They are engaging in a playful interaction, most likely running or rolling around on the grass. This image captures the amusing scene of a dog and a cat enjoying each other's company and sharing a fun moment.\n",
            "Chatbot Response (Translated): इस तस्वीर में एक कुत्ता और एक बिल्ली एक हरे मैदान में एक साथ मस्ती करते हुए दिखाई दे रहे हैं। ऐसा लगता है कि वे या तो घास पर दौड़ रहे हैं या घूम रहे हैं। यह तस्वीर एक हल्के-फुल्के पल को दर्शाती है जहाँ एक कुत्ता और एक बिल्ली एक साथ अच्छा समय बिता रहे हैं।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwcdoAmTy6Cr",
        "outputId": "ccaed3f3-6cae-464e-bb0c-b202716aa31c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Y09kMR50siH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}